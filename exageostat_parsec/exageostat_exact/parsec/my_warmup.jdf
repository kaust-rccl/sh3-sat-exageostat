extern "C" %{
/*
 * Copyright (c) 2017-2018 The Universiy of Tennessee and The Universiy
 *                         of Tennessee Research Foundation. All rights
 *                         reserved.
 */

#include "mix_precision_internal.h"
#include "include/dplasmajdf.h"
#include "include/dplasmaaux.h"

static int print_more = 0;

%}

descA  [ type = "parsec_tiled_matrix_dc_t *" ]

nb_cuda_devices      [ type = "int"   hidden = on default = 0 ]
cuda_device_index    [ type = "int *" hidden = on default = "NULL"]


/**************************************************
 *               potrf_bind_A                     *
 **************************************************/
bind_A(m, n)

// Execution space
m = 0 .. descA->nt-1
n = 0 .. m

// Parallel partitioning
:descA(m, n)

READ A <- descA(m, n)
       -> A Warmup(m, n)

BODY
{
#if defined(EXAGEOSTAT_USE_CUDA)
    if( nb_cuda_devices > 0 ) {
        int g = my_gpu_load( m, n, descA->nt, nb_cuda_devices, descA->nt, descA->nt);
        parsec_advise_data_on_device( _f_A->original,
                                    cuda_device_index[g],
                                    PARSEC_DEV_DATA_ADVICE_PREFERRED_DEVICE );
    }
#endif
}
END

Warmup(m, n)

// Execution space
m = 0 .. descA->nt-1
n = 0 .. m

// Parallel partitioning
:descA(m, n)

RW A <- A bind_A(m, n)
     -> A fake_task(m, n) 

BODY[type=CUDA weight=m+n+1]
{


}
END

BODY
{


}
END

fake_task(m, n)

// Execution space
m = 0 .. descA->nt-1
n = 0 .. m

// Parallel partitioning
:descA(m, n)

READ A <- A Warmup(m, n)

BODY
{


}
END


extern "C" %{

/**
 * @param [in] dcA:    the data, already distributed and allocated
 * @return the parsec object to schedule.
 */
parsec_taskpool_t*
parsec_my_warmup_New(parsec_tiled_matrix_dc_t *A)
{
    parsec_my_warmup_taskpool_t* taskpool = NULL;

#if defined(EXAGEOSTAT_USE_CUDA)
    /** Find all CUDA devices */
    int nb = 0;
    for(int i = 0; i < (int)parsec_nb_devices; i++) {
        parsec_device_module_t *device = parsec_mca_device_get(i);
        if( PARSEC_DEV_CUDA == device->type ) {
            nb++;
        }
    }

    if(nb == 0) {
        char hostname[256];
        gethostname(hostname, 256);
        if( print_more ) {
            fprintf(stderr, "No CUDA device found on rank %d on %s\n",
                    A->super.myrank, hostname);
        }
    }

    int *dev_index = (int*)malloc(nb * sizeof(int));
    nb = 0;
    for(int i = 0; i < (int)parsec_nb_devices; i++) {
        parsec_device_module_t *device = parsec_mca_device_get(i);
        if( PARSEC_DEV_CUDA == device->type ) {
            dev_index[nb++] = device->device_index;
        }
    }
#endif

    taskpool = parsec_my_warmup_new(A); 

#if defined(EXAGEOSTAT_USE_CUDA)
    taskpool->_g_nb_cuda_devices = nb;
    taskpool->_g_cuda_device_index = dev_index;
#endif

    parsec_matrix_add2arena(taskpool->arenas[PARSEC_my_warmup_DEFAULT_ARENA],
                            parsec_datatype_double_t, matrix_UpperLower,
                            1, A->mb, A->nb, A->mb,
                            PARSEC_ARENA_ALIGNMENT_SSE, -1 );

    return (parsec_taskpool_t*)taskpool;
}

/**
 * @param [inout] the parsec object to destroy
*/
void parsec_my_warmup_Destruct(parsec_taskpool_t *taskpool)
{
    parsec_my_warmup_taskpool_t *my_warmup_taskpool = (parsec_my_warmup_taskpool_t *)taskpool;
    parsec_matrix_del2arena(my_warmup_taskpool->arenas[PARSEC_my_warmup_DEFAULT_ARENA]);
    parsec_taskpool_free(taskpool);
}

/**
 * @brief allocate and generate dcA
 * 
 * @param [inout] dcA: the data, already distributed and allocated
 */
int parsec_my_warmup(parsec_context_t *parsec,
                     parsec_tiled_matrix_dc_t *A)
{
    parsec_taskpool_t *parsec_my_warmup = NULL;

    parsec_my_warmup = parsec_my_warmup_New(A); 

    if( parsec_my_warmup != NULL ){
        parsec_context_add_taskpool(parsec, parsec_my_warmup);
        parsec_context_start(parsec);
        parsec_context_wait(parsec);
        parsec_my_warmup_Destruct(parsec_my_warmup);
    }

    return 0;
}

%}
