extern "C" %{
/*
 * Copyright (c) 2010-2020 The University of Tennessee and The University
 *                         of Tennessee Research Foundation. All rights
 *                         reserved.
 */
#include "mix_precision_internal.h"
#include "include/dplasmajdf.h"

/* Print more info */
static int print_more = 0;
static int print_more_gpu = 0;

/*
 * Priorities used in this jdf:
 *      - spotrf_spotrf(k)    : (MT-k)**3
 *      - spotrf_ssyrk(k,m)   : (MT-m)**3 + 3 * (m - k)
 *      - spotrf_strsm(m,k)   : (MT-m)**3 + 3 * (m - k) * (2 * MT - k - m - 1)
 *      - spotrf_sgemm(m,n,k) : (MT-m)**3 + 3 * (m - n) * (2 * MT - m - n - 1) + 6 * (m - k)
 *
 * So max priority is:
 *      (MT - PRI_CHANGE)**3 + 3 * MT * (2 * MT - PRI_CHANGE - 1) + 6 * MT  < (MT**3 + 6 MT**2 + 3 MT)
 *
 * WARNING: If mt is greater than 1200, we might get integer overflow.
 */

%}

/* Globals
 */
uplo       [type = PLASMA_enum]
descA      [type = "parsec_tiled_matrix_dc_t*"]
INFO       [type = "int*"]

PRI_CHANGE [type = "int" hidden = on default = 0 ]
PRI_MAX    [type = "int" hidden = on default = "(descA->mt * ( 3 + descA->mt * ( 2 + descA->mt )))" ]
smallnb    [type = "int" hidden = on default = "descA->mb" ]

/* GPU workspace */
ws_handle_cusolver   [ type = "void *" hidden = on default = NULL ]
ws_handle_cublas_gpu        [ type = "void *" hidden = on default = NULL ]

nb_cuda_devices      [ type = "int"   hidden = on default = 1 ]
cuda_device_index    [ type = "int *" hidden = on default = "NULL"]


/**************************************************
 *               spotrf_bind_A                     *
 **************************************************/
spotrf_bind_A(m, n)

// Execution space
m = 0 .. descA->nt-1
n = 0 .. m 

// Parallel partitioning
:descA(m, n)

READ A <- descA(m, n)
       -> (m == 0 && n == 0) ? T spotrf_spotrf(0)                   [ type = SINGLE ]
       -> (m > 0  && n == 0) ? C spotrf_strsm(m, 0)   [ type = SINGLE ]
       -> (m == n && n > 0) ? T spotrf_ssyrk(0, m)    [ type = SINGLE ]
       -> (m != n && n > 0) ? C spotrf_sgemm(m, n, 0) [ type = SINGLE ]

BODY
{
#if defined(EXAGEOSTAT_USE_CUDA)
    if( nb_cuda_devices > 0 ) {
        int g = my_gpu_load( m, n, descA->nt, nb_cuda_devices, descA->nt, descA->nt);
        parsec_advise_data_on_device( _f_A->original,
                                    cuda_device_index[g],
                                    PARSEC_DEV_DATA_ADVICE_PREFERRED_DEVICE );
    }
#endif
}
END


/**************************************************
 *               spotrf_spotrf                     *
 **************************************************/
spotrf_spotrf(k) [high_priority = on] 

// Execution space
k = 0 .. descA->mt-1

// Parallel partitioning
:descA(k, k)

// Parameters
RW T <- (k == 0) ? A spotrf_bind_A(k, k) : T spotrf_ssyrk(k-1, k)
     -> T spotrf_strsm(k+1..descA->mt-1, k)
     -> descA(k, k)

; (k >= (descA->mt - PRI_CHANGE)) ? (descA->mt - k) * (descA->mt - k) * (descA->mt - k) : PRI_MAX

BODY [type=CUDA weight=k+1]
{
#if defined(EXAGEOSTAT_USE_CUDA)
    if( print_more_gpu ) printf("GPU_potrf %d ; nb_cuda_devices: %d ; cuda_device_index %d\n", k, nb_cuda_devices, gpu_device->cuda_index);

    int tempkn = k == descA->nt-1 ? descA->n - k*descA->nb : descA->nb;
    int ldak = descA->mb; 
    cusolverStatus_t status;

    /* Lookup workspace */
    parsec_potrf_workspace_t *_ws_handle = (parsec_potrf_workspace_t *)ws_handle_cusolver;
    parsec_potrf_stream_workspace_t stream_handle = lookup_gpu_workspace(gpu_device, gpu_stream, _ws_handle);

    /* Info used on GPU kernel */
    cusolverDnHandle_t handle = stream_handle.handle_cusolver;
    int *dev_info = (int *)(stream_handle.gpu_buffer + stream_handle.buffer_size * sizeof(float));
    float *gpu_buffer = (float *)stream_handle.gpu_buffer;
    int buffer_size = stream_handle.buffer_size;
    assert(NULL != gpu_buffer);

    /* GPU kernel */
    status = cusolverDnSpotrf(handle, CUBLAS_FILL_MODE_LOWER, tempkn, T, ldak, gpu_buffer, buffer_size, dev_info);
    assert(CUSOLVER_STATUS_SUCCESS == status);

    /* We are losing the iinfo in d_iinfo, because the kernel is asynchronous.
     * We should register a complete function to read d_iinfo back in CPU memory,
     * and update INFO with it... */
#endif
}
END

BODY
{
    int tempkm = k == descA->mt-1 ? descA->m - k*descA->mb : descA->mb;
    int iinfo = 0;
    int ldak = descA->mb; 

#if !defined(PARSEC_DRY_RUN)
    CORE_spotrf( uplo, tempkm, T, ldak, &iinfo );
    if ( iinfo != 0 && *INFO == 0 )
            *INFO = k*descA->mb+iinfo; /* Should return here */
#endif /* !defined(PARSEC_DRY_RUN) */

    printlog("CORE_spotrf( %d )\n\t( %s, %d, A(%d,%d)[%p], %d) return info = %d\n",
             k,
             plasma_const(uplo), tempkm, k, k, T, descA->mb, iinfo );
}
END

/**************************************************
 *               spotrf_strsm                      *
 **************************************************/
spotrf_strsm(m, k) [high_priority = on] 

// Execution space
m = 1 .. descA->mt-1
k = 0 .. m-1

// Parallel partitioning
: descA(m, k)

// Parameters
READ  T <- T spotrf_spotrf(k)

RW    C <- (k == 0) ? A spotrf_bind_A(m, k) : C spotrf_sgemm(m, k, k-1)
        -> A spotrf_ssyrk(k, m)
        -> A spotrf_sgemm(m, k+1..m-1, k)
        -> B spotrf_sgemm(m+1..descA->mt-1, m, k)
        -> descA(m, k)

; (m >= (descA->mt - PRI_CHANGE)) ? (descA->mt - m) * (descA->mt - m) * (descA->mt - m) + 3 * ((2 * descA->mt) - k - m - 1) * (m - k) : PRI_MAX

BODY [type=CUDA weight=(m+1-k)]
{
#if defined(EXAGEOSTAT_USE_CUDA)
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
    int ldak = descA->mb; 
    int ldam = descA->mb; 
    const float alpha = (float)1.0;

    /* Get handle_cublas */ 
    parsec_potrf_workspace_t *_ws_handle = (parsec_potrf_workspace_t *)ws_handle_cublas_gpu;
    parsec_potrf_stream_workspace_t stream_handle = lookup_gpu_workspace(gpu_device, gpu_stream, _ws_handle);
    cublasHandle_t handle = stream_handle.handle_cublas;

    cublasStatus_t status;
    cublasSetStream( handle, parsec_body.stream );

    status = cublasStrsm( handle, CUBLAS_SIDE_RIGHT, CUBLAS_FILL_MODE_LOWER,
                          CUBLAS_OP_T, CUBLAS_OP_N,
                          tempmm, descA->mb,
                          &alpha, T /*A(k, k)*/, ldak,
                                  C /*A(m, k)*/, ldam);
#endif
}
END

BODY
{
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
    int ldak = descA->mb; 
    int ldam = descA->mb; 

    CORE_strsm(PlasmaRight, PlasmaLower, PlasmaTrans, PlasmaNonUnit,
               tempmm, descA->nb,
               (float)1.0, T /*A(k, k)*/, ldak,
                                C /*A(m, k)*/, ldam);

    printlog("CORE_strsm( %d, %d )\n\t( %s, %s, %s, %s, %d, %d, %f, A(%d,%d)[%p], %d,  A(%d,%d)[%p], %d)\n",
             m, k,
             plasma_const( PlasmaRight ), plasma_const( PlasmaLower ),
             plasma_const( PlasmaTrans ), plasma_const( PlasmaNonUnit ),
             tempmm, descA->nb,
             1.0, k, k, T, ldak,
                  m, k, C, ldam);
}
END


/**************************************************
 *               spotrf_ssyrk                      *
 **************************************************/
spotrf_ssyrk(k, m) [high_priority = on]

// Execution space
k = 0   .. descA->mt-2
m = k+1 .. descA->mt-1

// Parallel partitioning
: descA(m, m)

//Parameters
READ  A <- C spotrf_strsm(m, k)

RW    T <- (k == 0)   ? A spotrf_bind_A(m, m) : T spotrf_ssyrk(k-1, m)
        -> (m == k+1) ? T spotrf_spotrf(m)  : T spotrf_ssyrk(k+1, m)

; (m >= (descA->mt - PRI_CHANGE)) ? (descA->mt - m) * (descA->mt - m) * (descA->mt - m) + 3 * (m - k) : PRI_MAX

BODY [type=CUDA weight=(m+1-k)]
{
#if defined(EXAGEOSTAT_USE_CUDA)
    int tempmm = m == descA->mt-1 ? descA->m - m*descA->mb : descA->mb;
    int ldam = descA->mb;
    const float alpha = (float)-1.0;
    const float beta = (float)1.0;
    if( print_more_gpu ) printf("GPU_syrk: %d %d : cuda_index %d\n", m, k, gpu_device->cuda_index);

    /* Get handle_cublas */
    parsec_potrf_workspace_t *_ws_handle = (parsec_potrf_workspace_t *)ws_handle_cublas_gpu;
    parsec_potrf_stream_workspace_t stream_handle = lookup_gpu_workspace(gpu_device, gpu_stream, _ws_handle);
    cublasHandle_t handle = stream_handle.handle_cublas;

    cublasStatus_t status;
    cublasSetStream( handle, parsec_body.stream );

    status = cublasSsyrk( handle, CUBLAS_FILL_MODE_LOWER, CUBLAS_OP_N,
                    tempmm, descA->mb,
                    &alpha, A  /*A(m, k)*/, ldam,
                    &beta,  T  /*A(m, m)*/, ldam);
#endif
}
END

BODY
{
    int tempmm = m == descA->mt-1 ? descA->m - m*descA->mb : descA->mb;
    int ldam = descA->mb; 

#if !defined(PARSEC_DRY_RUN)
    CORE_ssyrk(PlasmaLower, PlasmaNoTrans,
               tempmm, descA->mb,
               (float)-1.0, A /*A(m, k)*/, ldam,
               (float) 1.0, T /*A(m, m)*/, ldam);
#endif  /* !defined(PARSEC_DRY_RUN) */

    printlog(
             "CORE_ssyrk( %d, %d )\n\t( %s, %s, %d, %d, %f, A(%d,%d)[%p], %d, %f, A(%d,%d)[%p], %d)\n",
             k, m,
             plasma_const( PlasmaLower ), plasma_const( PlasmaNoTrans ),
             tempmm, descA->mb,
             -1.0, m, k, A, ldam,
              1.0, m, m, T, ldam);
}
END

/**************************************************
 *               spotrf_sgemm                      *
 **************************************************/
// Name
spotrf_sgemm(m, n, k)

// Execution space
k = 0   .. descA->mt-3
m = k+2 .. descA->mt-1
n = k+1 .. m-1

// Parallel partitioning
: descA(m, n)

// Parameters
READ  A <- C spotrf_strsm(m, k)
READ  B <- C spotrf_strsm(n, k)

RW    C <- (k == 0) ? A spotrf_bind_A(m, n) : C spotrf_sgemm(m, n, k-1)
        -> (n == k+1) ? C spotrf_strsm(m, n) : C spotrf_sgemm(m, n, k+1)

; (m >= (descA->mt - PRI_CHANGE)) ? (descA->mt - m) * (descA->mt - m) * (descA->mt - m) + 3 * ((2 * descA->mt) - m - n - 3) * (m - n) + 6 * (m - k) : PRI_MAX

BODY [type=CUDA weight=(n+1-k)]
{
#if defined(EXAGEOSTAT_USE_CUDA)
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
    int ldam = descA->mb; 
    int ldan = descA->mb; 
    const float alpha = (float)-1.0;
    const float beta = (float)1.0;

    cublasStatus_t status;
    cudaError_t err;

    /* Get handle_cublas */
    parsec_potrf_workspace_t * _ws_handle = (parsec_potrf_workspace_t *)ws_handle_cublas_gpu;
    parsec_potrf_stream_workspace_t stream_handle = lookup_gpu_workspace(gpu_device, gpu_stream, _ws_handle);
    cublasHandle_t handle = stream_handle.handle_cublas;

    cublasSetStream( handle, parsec_body.stream );

    status = cublasSgemm( handle, CUBLAS_OP_N, CUBLAS_OP_T,
             tempmm, descA->mb, descA->mb,
             &alpha, A, ldam,
                     B, ldan,
             &beta,  C, ldam );
#endif

}
END

BODY
{
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
    int ldam = descA->mb; 
    int ldan = descA->mb; 

    CORE_sgemm(PlasmaNoTrans, PlasmaTrans,
               tempmm, descA->mb, descA->mb,
               (float)-1.0, A /*A(m, k)*/, ldam,
                            B /*A(n, k)*/, ldan,
               (float) 1.0, C /*A(m, n)*/, ldam);

    printlog("CORE_sgemm( %d, %d, %d )\n\t( %s, %s, %d, %d, %d, %f, A(%d,%d)[%p], %d, A(%d,%d)[%p], %d, %f, A(%d,%d)[%p], %d)\n",
             m, n, k,
             plasma_const( PlasmaNoTrans ),  plasma_const( PlasmaTrans ),
             tempmm, descA->mb, descA->mb,
             -1.0, m, k, A, ldam,
                   n, k, B, ldan,
              1.0, m, n, C, ldam);
}
END
